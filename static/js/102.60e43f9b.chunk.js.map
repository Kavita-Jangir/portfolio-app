{"version":3,"sources":["D:/react_app/app_1/node_modules/@codemirror/legacy-modes/mode/velocity.js"],"names":["parseWords","str","obj","words","split","i","length","__webpack_require__","r","__webpack_exports__","d","velocity","keywords","functions","specials","isOperatorChar","chain","stream","state","f","tokenize","tokenBase","beforeParams","ch","next","inString","inParams","lastTokenWasBuiltin","tokenString","test","eatWhile","eat","tokenComment","match","tokenUnparsed","skipToEnd","propertyIsEnumerable","current","word","peek","toLowerCase","pos","string","charAt","quote","escaped","end","maybeEnd","name","startState","token","eatSpace","languageData","commentTokens","line","block","open","close"],"mappings":"4FAAA,SAAAA,EAAAC,GAGA,IAFA,IAAAC,EAAA,GACAC,EAAAF,EAAAG,MAAA,KACAC,EAAA,EAAiBA,EAAAF,EAAAG,SAAkBD,EAAAH,EAAAC,EAAAE,KAAA,EACnC,OAAAH,EAJAK,EAAAC,EAAAC,GAAAF,EAAAG,EAAAD,EAAA,6BAAAE,IAMA,IAAAC,EAAAZ,EAAA,mEACAa,EAAAb,EAAA,2JACAc,EAAAd,EAAA,oOACAe,EAAA,oBACA,SAAAC,EAAAC,EAAAC,EAAAC,GAEA,OADAD,EAAAE,SAAAD,EACAA,EAAAF,EAAAC,GAEA,SAAAG,EAAAJ,EAAAC,GACA,IAAAI,EAAAJ,EAAAI,aACAJ,EAAAI,cAAA,EACA,IAAAC,EAAAN,EAAAO,OAEA,QAAAD,IAAAL,EAAAO,UAAAP,EAAAQ,SAEA,OADAR,EAAAS,qBAAA,EACAX,EAAAC,EAAAC,EAAAU,EAAAL,IAGA,QAAAA,EAQA,uBAAyBM,KAAAN,GAKzB,MAJA,KAAAA,GAAAD,EAAAJ,EAAAQ,UAAA,EAAyD,KAAAH,IACzDL,EAAAQ,UAAA,EACAR,EAAAS,qBAAA,GAEA,KAGA,QAAAE,KAAAN,GAGA,OAFAL,EAAAS,qBAAA,EACAV,EAAAa,SAAA,UACA,SAGA,QAAAP,GAAAN,EAAAc,IAAA,KAEA,OADAb,EAAAS,qBAAA,EACAX,EAAAC,EAAAC,EAAAc,GAGA,QAAAT,GAAAN,EAAAgB,MAAA,YAEA,OADAf,EAAAS,qBAAA,EACAX,EAAAC,EAAAC,EAAAgB,GAGA,QAAAX,GAAAN,EAAAc,IAAA,KAGA,OAFAb,EAAAS,qBAAA,EACAV,EAAAkB,YACA,UAGA,QAAAZ,EAIA,OAHAN,EAAAc,IAAA,KACAd,EAAAa,SAAA,kBAEAhB,KAAAsB,qBAAAnB,EAAAoB,WACA,WAEAnB,EAAAS,qBAAA,EACAT,EAAAI,cAAA,EACA,WAIA,GAAAP,EAAAc,KAAAN,GAGA,OAFAL,EAAAS,qBAAA,EACAV,EAAAa,SAAAf,GACA,WAGAE,EAAAa,SAAA,cACA,IAAAQ,EAAArB,EAAAoB,UAEA,OAAAzB,KAAAwB,qBAAAE,GAAA,UAEAzB,KAAAuB,qBAAAE,IAAArB,EAAAoB,UAAAJ,MAAA,4BAAAhB,EAAAsB,UAAA1B,MAAAuB,qBAAAE,EAAAE,iBACAtB,EAAAI,cAAA,EACAJ,EAAAS,qBAAA,EACA,WAEAT,EAAAO,UACAP,EAAAS,qBAAA,EACA,UAEAV,EAAAwB,IAAAH,EAAAhC,QAAA,KAAAW,EAAAyB,OAAAC,OAAA1B,EAAAwB,IAAAH,EAAAhC,OAAA,IAAAY,EAAAS,oBAAA,WAEAT,EAAAS,qBAAA,EACA,MAxEA,OADAT,EAAAS,qBAAA,EACAT,EAAAO,UACAP,EAAAO,UAAA,EACA,UACKP,EAAAQ,SAAAV,EAAAC,EAAAC,EAAAU,EAAAL,SAAA,EAwEL,SAAAK,EAAAgB,GACA,gBAAA3B,EAAAC,GAIA,IAHA,IACAM,EADAqB,GAAA,EAEAC,GAAA,EACA,OAAAtB,EAAAP,EAAAO,SAAA,CACA,GAAAA,GAAAoB,IAAAC,EAAA,CACAC,GAAA,EACA,MAEA,QAAAF,GAAA,KAAA3B,EAAAsB,SAAAM,EAAA,CACA3B,EAAAO,UAAA,EACAqB,GAAA,EACA,MAEAD,MAAA,MAAArB,EAGA,OADAsB,IAAA5B,EAAAE,SAAAC,GACA,UAGA,SAAAW,EAAAf,EAAAC,GAGA,IAFA,IACAK,EADAwB,GAAA,EAEAxB,EAAAN,EAAAO,QAAA,CACA,QAAAD,GAAAwB,EAAA,CACA7B,EAAAE,SAAAC,EACA,MAEA0B,EAAA,KAAAxB,EAEA,gBAEA,SAAAW,EAAAjB,EAAAC,GAGA,IAFA,IACAK,EADAwB,EAAA,EAEAxB,EAAAN,EAAAO,QAAA,CACA,QAAAD,GAAA,GAAAwB,EAAA,CACA7B,EAAAE,SAAAC,EACA,MAEA,KAAAE,EAAAwB,IAA8B,KAAAxB,IAAAwB,EAAA,GAE9B,aAIO,IAAApC,EAAA,CACPqC,KAAA,WACAC,WAAA,WACA,OACA7B,SAAAC,EACAC,cAAA,EACAI,UAAA,EACAD,UAAA,EACAE,qBAAA,IAGAuB,MAAA,SAAAjC,EAAAC,GACA,OAAAD,EAAAkC,WAAA,KACAjC,EAAAE,SAAAH,EAAAC,IAEAkC,aAAA,CACAC,cAAA,CACAC,KAAA,KACAC,MAAA,CACAC,KAAA,KACAC,MAAA","file":"static/js/102.60e43f9b.chunk.js","sourcesContent":["function parseWords(str) {\n  var obj = {},\n    words = str.split(\" \");\n  for (var i = 0; i < words.length; ++i) obj[words[i]] = true;\n  return obj;\n}\nvar keywords = parseWords(\"#end #else #break #stop #[[ #]] \" + \"#{end} #{else} #{break} #{stop}\");\nvar functions = parseWords(\"#if #elseif #foreach #set #include #parse #macro #define #evaluate \" + \"#{if} #{elseif} #{foreach} #{set} #{include} #{parse} #{macro} #{define} #{evaluate}\");\nvar specials = parseWords(\"$foreach.count $foreach.hasNext $foreach.first $foreach.last $foreach.topmost $foreach.parent.count $foreach.parent.hasNext $foreach.parent.first $foreach.parent.last $foreach.parent $velocityCount $!bodyContent $bodyContent\");\nvar isOperatorChar = /[+\\-*&%=<>!?:\\/|]/;\nfunction chain(stream, state, f) {\n  state.tokenize = f;\n  return f(stream, state);\n}\nfunction tokenBase(stream, state) {\n  var beforeParams = state.beforeParams;\n  state.beforeParams = false;\n  var ch = stream.next();\n  // start of unparsed string?\n  if (ch == \"'\" && !state.inString && state.inParams) {\n    state.lastTokenWasBuiltin = false;\n    return chain(stream, state, tokenString(ch));\n  }\n  // start of parsed string?\n  else if (ch == '\"') {\n    state.lastTokenWasBuiltin = false;\n    if (state.inString) {\n      state.inString = false;\n      return \"string\";\n    } else if (state.inParams) return chain(stream, state, tokenString(ch));\n  }\n  // is it one of the special signs []{}().,;? Separator?\n  else if (/[\\[\\]{}\\(\\),;\\.]/.test(ch)) {\n    if (ch == \"(\" && beforeParams) state.inParams = true;else if (ch == \")\") {\n      state.inParams = false;\n      state.lastTokenWasBuiltin = true;\n    }\n    return null;\n  }\n  // start of a number value?\n  else if (/\\d/.test(ch)) {\n    state.lastTokenWasBuiltin = false;\n    stream.eatWhile(/[\\w\\.]/);\n    return \"number\";\n  }\n  // multi line comment?\n  else if (ch == \"#\" && stream.eat(\"*\")) {\n    state.lastTokenWasBuiltin = false;\n    return chain(stream, state, tokenComment);\n  }\n  // unparsed content?\n  else if (ch == \"#\" && stream.match(/ *\\[ *\\[/)) {\n    state.lastTokenWasBuiltin = false;\n    return chain(stream, state, tokenUnparsed);\n  }\n  // single line comment?\n  else if (ch == \"#\" && stream.eat(\"#\")) {\n    state.lastTokenWasBuiltin = false;\n    stream.skipToEnd();\n    return \"comment\";\n  }\n  // variable?\n  else if (ch == \"$\") {\n    stream.eat(\"!\");\n    stream.eatWhile(/[\\w\\d\\$_\\.{}-]/);\n    // is it one of the specials?\n    if (specials && specials.propertyIsEnumerable(stream.current())) {\n      return \"keyword\";\n    } else {\n      state.lastTokenWasBuiltin = true;\n      state.beforeParams = true;\n      return \"builtin\";\n    }\n  }\n  // is it a operator?\n  else if (isOperatorChar.test(ch)) {\n    state.lastTokenWasBuiltin = false;\n    stream.eatWhile(isOperatorChar);\n    return \"operator\";\n  } else {\n    // get the whole word\n    stream.eatWhile(/[\\w\\$_{}@]/);\n    var word = stream.current();\n    // is it one of the listed keywords?\n    if (keywords && keywords.propertyIsEnumerable(word)) return \"keyword\";\n    // is it one of the listed functions?\n    if (functions && functions.propertyIsEnumerable(word) || stream.current().match(/^#@?[a-z0-9_]+ *$/i) && stream.peek() == \"(\" && !(functions && functions.propertyIsEnumerable(word.toLowerCase()))) {\n      state.beforeParams = true;\n      state.lastTokenWasBuiltin = false;\n      return \"keyword\";\n    }\n    if (state.inString) {\n      state.lastTokenWasBuiltin = false;\n      return \"string\";\n    }\n    if (stream.pos > word.length && stream.string.charAt(stream.pos - word.length - 1) == \".\" && state.lastTokenWasBuiltin) return \"builtin\";\n    // default: just a \"word\"\n    state.lastTokenWasBuiltin = false;\n    return null;\n  }\n}\nfunction tokenString(quote) {\n  return function (stream, state) {\n    var escaped = false,\n      next,\n      end = false;\n    while ((next = stream.next()) != null) {\n      if (next == quote && !escaped) {\n        end = true;\n        break;\n      }\n      if (quote == '\"' && stream.peek() == '$' && !escaped) {\n        state.inString = true;\n        end = true;\n        break;\n      }\n      escaped = !escaped && next == \"\\\\\";\n    }\n    if (end) state.tokenize = tokenBase;\n    return \"string\";\n  };\n}\nfunction tokenComment(stream, state) {\n  var maybeEnd = false,\n    ch;\n  while (ch = stream.next()) {\n    if (ch == \"#\" && maybeEnd) {\n      state.tokenize = tokenBase;\n      break;\n    }\n    maybeEnd = ch == \"*\";\n  }\n  return \"comment\";\n}\nfunction tokenUnparsed(stream, state) {\n  var maybeEnd = 0,\n    ch;\n  while (ch = stream.next()) {\n    if (ch == \"#\" && maybeEnd == 2) {\n      state.tokenize = tokenBase;\n      break;\n    }\n    if (ch == \"]\") maybeEnd++;else if (ch != \" \") maybeEnd = 0;\n  }\n  return \"meta\";\n}\n// Interface\n\nexport var velocity = {\n  name: \"velocity\",\n  startState: function startState() {\n    return {\n      tokenize: tokenBase,\n      beforeParams: false,\n      inParams: false,\n      inString: false,\n      lastTokenWasBuiltin: false\n    };\n  },\n  token: function token(stream, state) {\n    if (stream.eatSpace()) return null;\n    return state.tokenize(stream, state);\n  },\n  languageData: {\n    commentTokens: {\n      line: \"##\",\n      block: {\n        open: \"#*\",\n        close: \"*#\"\n      }\n    }\n  }\n};"],"sourceRoot":""}