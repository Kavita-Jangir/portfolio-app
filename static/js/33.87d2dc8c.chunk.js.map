{"version":3,"sources":["D:/react_app/app_1/node_modules/@codemirror/legacy-modes/mode/crystal.js"],"names":["wordRegExp","words","end","RegExp","join","chain","tokenize","stream","state","push","__webpack_require__","r","__webpack_exports__","d","crystal","operators","conditionalOperators","indexingOperators","anotherOperators","idents","types","keywords","atomWords","indentKeywords","indentExpressionKeywords","dedentKeywordsArray","dedentKeywords","dedentPunctualsArray","dedentPunctuals","nextTokenizer","def","tokenFollowIdent","fun","macro","eatSpace","matched","match","eat","pop","class","tokenFollowType","module","struct","lib","enum","union","matching","[","{","(","<","tokenBase","lastToken","tokenMacro","peek","skipToEnd","current","test","blocks","indexOf","currentIndent","lastStyle","hasOwnProperty","tokenNest","tokenQuote","delim","style","embed","next","phrase","sol","escaped","tokenHereDoc","begin","started","length","nextStyle","ch","name","startState","token","indent","textAfter","cx","replace","unit","languageData","indentOnInput","concat","commentTokens","line"],"mappings":"2FAAA,SAAAA,EAAAC,EAAAC,GACA,WAAAC,QAAAD,EAAA,cAAAD,EAAAG,KAAA,UAAAF,EAAA,YAEA,SAAAG,EAAAC,EAAAC,EAAAC,GAEA,OADAA,EAAAF,SAAAG,KAAAH,GACAA,EAAAC,EAAAC,GALAE,EAAAC,EAAAC,GAAAF,EAAAG,EAAAD,EAAA,4BAAAE,IAOA,IAAAC,EAAA,+BACAC,EAAA,wCACAC,EAAA,iBACAC,EAAA,4BACAC,EAAA,iDACAC,EAAA,iDACAC,EAAArB,EAAA,6bACAsB,EAAAtB,EAAA,+BAEAuB,EAAAvB,EADA,iFAGAwB,EAAAxB,EADA,uDAEAyB,EAAA,yCACAC,EAAA1B,EAAAyB,GACAE,EAAA,aAAuC,OACvCC,EAAA,IAAAzB,OAAA,OAAAwB,EAAAvB,KAAA,WACAyB,EAAA,CACAC,IAAAC,EACAC,IAAAD,EACAE,MAmNA,SAAA1B,EAAAC,GACA,GAAAD,EAAA2B,WACA,YAEA,IAAAC,EACA,GAAAA,EAAA5B,EAAA6B,MAAAjB,GAAA,CACA,UAAAgB,EACA,gBAEA5B,EAAA8B,IAAA,QAGA,OADA7B,EAAAF,SAAAgC,MACA,OA9NAC,MAAAC,EACAC,OAAAD,EACAE,OAAAF,EACAG,IAAAH,EACAI,KAAAJ,EACAK,MAAAL,GAEAM,EAAA,CACAC,IAAA,IACAC,IAAI,IACJC,IAAA,IACAC,IAAA,KAEA,SAAAC,EAAA5C,EAAAC,GACA,GAAAD,EAAA2B,WACA,YAIA,SAAA1B,EAAA4C,WAAA7C,EAAA6B,MAAA,MAAgD,GAChD,OAAA/B,EAAAgD,EAAA,SAAA9C,EAAAC,GAEA,SAAAA,EAAA4C,WAAA7C,EAAA6B,MAAA,MAAiD,GACjD,OAAA/B,EAAAgD,EAAA,IAA8B,KAAK9C,EAAAC,GAInC,QAAAD,EAAA+C,OAEA,OADA/C,EAAAgD,YACA,UAIA,IAAApB,EACA,GAAA5B,EAAA6B,MAAAjB,GAGA,OAFAZ,EAAA8B,IAAA,QACAF,EAAA5B,EAAAiD,UACAjD,EAAA8B,IAAA,KACA,OACK,KAAA7B,EAAA4C,UACL,WACK/B,EAAAoC,KAAAtB,IACLZ,EAAAkC,KAAAtB,GACA,OAAAA,GAAA3B,EAAAkD,OAAAC,QAAA,kBAAAxB,GAAA,YAAA3B,EAAA4C,YACA5C,EAAAkD,OAAAjD,KAAA0B,GACA3B,EAAAoD,eAAA,GAEO,YAAApD,EAAAqD,WAAArD,EAAAqD,YAAArC,EAAAiC,KAAAtB,GAGA,OAAAA,IACP3B,EAAAkD,OAAApB,MACA9B,EAAAoD,eAAA,IAJApD,EAAAkD,OAAAjD,KAAA0B,GACA3B,EAAAoD,eAAA,GAKA/B,EAAAiC,eAAA3B,IACA3B,EAAAF,SAAAG,KAAAoB,EAAAM,IAEA,WACKb,EAAAmC,KAAAtB,GACL,OAEA,WAKA,GAAA5B,EAAA8B,IAAA,KACA,WAAA9B,EAAA+C,OACAjD,EAAA0D,EAAA,gBAAAxD,EAAAC,IAEAD,EAAA8B,IAAA,KACA9B,EAAA6B,MAAAjB,IAAAZ,EAAA6B,MAAAhB,GACA,gBAIA,GAAAb,EAAA6B,MAAAhB,GACA,YAIA,GAAAb,EAAA8B,IAAA,KACA,OAAA9B,EAAA8B,IAAA,KACAhC,EAAA2D,EAAA,eAAAzD,EAAAC,GACKD,EAAA6B,MAAAjB,IAAAZ,EAAA6B,MAAAhB,IAAAb,EAAA6B,MAAArB,IAAAR,EAAA6B,MAAApB,IAAAT,EAAA6B,MAAAnB,GACL,QAEAV,EAAA8B,IAAA,KACA,YAIA,GAAA9B,EAAA8B,IAAA,KACA,OAAAhC,EAAA2D,EAAA,iBAAAzD,EAAAC,GAIA,QAAAD,EAAA+C,OAAA,CACA,IAEAW,EAFAC,EAAA,SACAC,GAAA,EAEA,GAAA5D,EAAA6B,MAAA,MAEA8B,EAAA,iBACAD,EAAA1D,EAAA6D,YACK,GAAA7D,EAAA6B,MAAA,MACL+B,GAAA,EACAF,EAAA1D,EAAA6D,YACK,GAAA7D,EAAA6B,MAAA,MACL+B,GAAA,EACAF,EAAA1D,EAAA6D,YAEA,GAAAH,EAAA1D,EAAA6B,MAAA,gBACA6B,IAAA,OACO,IAAA1D,EAAA6B,MAAA,8CAEP,aACO,GAAA7B,EAAA8B,IAAA,KAEP,iBAMA,OAHAS,EAAAgB,eAAAG,KACAA,EAAAnB,EAAAmB,IAEA5D,EAAA2D,EAAAC,EAAAC,EAAAC,GAAA5D,EAAAC,GAIA,OAAA2B,EAAA5B,EAAA6B,MAAA,yBACA/B,EAiJA,SAAAgE,EAAAF,GACA,gBAAA5D,EAAAC,GACA,GAAAD,EAAA+D,QACA/D,EAAA2B,WACA3B,EAAA6B,MAAAiC,IAEA,OADA7D,EAAAF,SAAAgC,MACA,SAIA,IADA,IAAAiC,GAAA,EACAhE,EAAA+C,QACA,GAAAiB,EAeAhE,EAAA6D,OACAG,GAAA,MAhBA,CACA,GAAAhE,EAAA6B,MAAA,MAA2B,GAE3B,OADA5B,EAAAF,SAAAG,KAAA4C,EAAA,UACA,SAEA,GAAA9C,EAAA6B,MAAA,MAA4B,GAE5B,OADA5B,EAAAF,SAAAG,KAAA4C,EAAA,IAA2C,MAC3C,SAEA,GAAAc,GAAA5D,EAAA6B,MAAA,MAAqC,GAErC,OADA5B,EAAAF,SAAAG,KAAAsD,EAAA,KAA2C,IAAK,SAChD,SAEAQ,EAAAJ,GAAA,MAAA5D,EAAA6D,OAMA,gBA/KAI,CAAArC,EAAA,IAAAA,EAAA,IAAA5B,EAAAC,GAIAD,EAAA8B,IAAA,MACA9B,EAAA6B,MAAA,kFACA7B,EAAA8B,IAAA,KACA,QAIA9B,EAAA8B,IAAA,MACA9B,EAAA8B,IAAA,KACA9B,EAAA6B,MAAA,kBACK7B,EAAA8B,IAAA,KACL9B,EAAA6B,MAAA,YACK7B,EAAA8B,IAAA,MACL9B,EAAA6B,MAAA,WAEA,UAEA7B,EAAA8B,IAAA,QACA9B,EAAA6B,MAAA,yCACA,UAIA7B,EAAA6B,MAAArB,IACAR,EAAA8B,IAAA,KACA,YAEA9B,EAAA6B,MAAApB,IAAAT,EAAA6B,MAAAlB,GACA,YAIAiB,EAAA5B,EAAA6B,MAAA,SAAiC,IAEjC/B,EAAA0D,EADA5B,IAAA,GACAW,EAAAX,GAAA,MAAA5B,EAAAC,GAIAD,EAAA8B,IAAA,OACA9B,EAAA6D,OACA,SAEA7D,EAAA6D,OACA,MAEA,SAAAL,EAAAU,EAAAvE,EAAAgE,EAAAQ,GACA,gBAAAnE,EAAAC,GACA,IAAAkE,GAAAnE,EAAA6B,MAAAqC,GAGA,OAFAjE,EAAAF,SAAAE,EAAAF,SAAAqE,OAAA,GAAAZ,EAAAU,EAAAvE,EAAAgE,GAAA,GACA1D,EAAAoD,eAAA,EACAM,EAEA,IAAAU,EAAAzB,EAAA5C,EAAAC,GAMA,OALAD,EAAAiD,YAAAtD,IACAM,EAAAF,SAAAgC,MACA9B,EAAAoD,eAAA,EACAgB,EAAAV,GAEAU,GAGA,SAAAvB,EAAAoB,EAAAvE,EAAAwE,GACA,gBAAAnE,EAAAC,GACA,OAAAkE,GAAAnE,EAAA6B,MAAA,IAAmCqC,IACnCjE,EAAAoD,eAAA,EACApD,EAAAF,SAAAE,EAAAF,SAAAqE,OAAA,GAAAtB,EAAAoB,EAAAvE,GAAA,GACA,QAEAK,EAAA6B,MAAAlC,EAAA,MACAM,EAAAoD,eAAA,EACApD,EAAAF,SAAAgC,MACA,QAEAa,EAAA5C,EAAAC,IAiBA,SAAAuB,EAAAxB,EAAAC,GACA,OAAAD,EAAA2B,WACA,MAEA3B,EAAA6B,MAAAjB,GACAZ,EAAA8B,IAAA,QAEA9B,EAAA6B,MAAArB,IAAAR,EAAA6B,MAAApB,IAAAT,EAAA6B,MAAAnB,GAEAT,EAAAF,SAAAgC,MACA,OAEA,SAAAE,EAAAjC,EAAAC,GACA,OAAAD,EAAA2B,WACA,MAEA3B,EAAA6B,MAAAhB,GACAZ,EAAAF,SAAAgC,MACA,OAEA,SAAA0B,EAAA9D,EAAAgE,EAAAC,GACA,gBAAA5D,EAAAC,GAEA,IADA,IAAA+D,GAAA,EACAhE,EAAA+C,QACA,GAAAiB,EAoBAhE,EAAA6D,OACAG,GAAA,MArBA,CACA,GAAAhE,EAAA6B,MAAA,MAA2B,GAE3B,OADA5B,EAAAF,SAAAG,KAAA4C,EAAA,UACAa,EAEA,GAAA3D,EAAA6B,MAAA,MAA4B,GAE5B,OADA5B,EAAAF,SAAAG,KAAA4C,EAAA,IAA2C,MAC3Ca,EAEA,GAAAC,GAAA5D,EAAA6B,MAAA,MAAqC,GAErC,OADA5B,EAAAF,SAAAG,KAAAsD,EAAA,KAA2C,IAAK,SAChDG,EAEA,IAAAW,EAAAtE,EAAA6D,OACA,GAAAS,GAAA3E,EAEA,OADAM,EAAAF,SAAAgC,MACA4B,EAEAK,EAAAJ,GAAA,MAAAU,EAMA,OAAAX,GAoCO,IAAApD,EAAA,CACPgE,KAAA,UACAC,WAAA,WACA,OACAzE,SAAA,CAAA6C,GACAS,cAAA,EACAR,UAAA,KACAS,UAAA,KACAH,OAAA,KAGAsB,MAAA,SAAAzE,EAAAC,GACA,IAAA0D,EAAA1D,EAAAF,SAAAE,EAAAF,SAAAqE,OAAA,GAAApE,EAAAC,GACAwE,EAAAzE,EAAAiD,UAKA,OAJAU,GAAA,WAAAA,IACA1D,EAAA4C,UAAA4B,EACAxE,EAAAqD,UAAAK,GAEAA,GAEAe,OAAA,SAAAzE,EAAA0E,EAAAC,GAEA,OADAD,IAAAE,QAAA,mCAA4D,IAC5D1D,EAAA+B,KAAAyB,IAAAtD,EAAA6B,KAAAyB,GACAC,EAAAE,MAAA7E,EAAAoD,cAAA,GAEAuB,EAAAE,KAAA7E,EAAAoD,eAEA0B,aAAA,CACAC,cAAAvF,EAAA2B,EAAA6D,OAAA/D,IAAA,GACAgE,cAAA,CACAC,KAAA","file":"static/js/33.87d2dc8c.chunk.js","sourcesContent":["function wordRegExp(words, end) {\n  return new RegExp((end ? \"\" : \"^\") + \"(?:\" + words.join(\"|\") + \")\" + (end ? \"$\" : \"\\\\b\"));\n}\nfunction chain(tokenize, stream, state) {\n  state.tokenize.push(tokenize);\n  return tokenize(stream, state);\n}\nvar operators = /^(?:[-+/%|&^]|\\*\\*?|[<>]{2})/;\nvar conditionalOperators = /^(?:[=!]~|===|<=>|[<>=!]=?|[|&]{2}|~)/;\nvar indexingOperators = /^(?:\\[\\][?=]?)/;\nvar anotherOperators = /^(?:\\.(?:\\.{2})?|->|[?:])/;\nvar idents = /^[a-z_\\u009F-\\uFFFF][a-zA-Z0-9_\\u009F-\\uFFFF]*/;\nvar types = /^[A-Z_\\u009F-\\uFFFF][a-zA-Z0-9_\\u009F-\\uFFFF]*/;\nvar keywords = wordRegExp([\"abstract\", \"alias\", \"as\", \"asm\", \"begin\", \"break\", \"case\", \"class\", \"def\", \"do\", \"else\", \"elsif\", \"end\", \"ensure\", \"enum\", \"extend\", \"for\", \"fun\", \"if\", \"include\", \"instance_sizeof\", \"lib\", \"macro\", \"module\", \"next\", \"of\", \"out\", \"pointerof\", \"private\", \"protected\", \"rescue\", \"return\", \"require\", \"select\", \"sizeof\", \"struct\", \"super\", \"then\", \"type\", \"typeof\", \"uninitialized\", \"union\", \"unless\", \"until\", \"when\", \"while\", \"with\", \"yield\", \"__DIR__\", \"__END_LINE__\", \"__FILE__\", \"__LINE__\"]);\nvar atomWords = wordRegExp([\"true\", \"false\", \"nil\", \"self\"]);\nvar indentKeywordsArray = [\"def\", \"fun\", \"macro\", \"class\", \"module\", \"struct\", \"lib\", \"enum\", \"union\", \"do\", \"for\"];\nvar indentKeywords = wordRegExp(indentKeywordsArray);\nvar indentExpressionKeywordsArray = [\"if\", \"unless\", \"case\", \"while\", \"until\", \"begin\", \"then\"];\nvar indentExpressionKeywords = wordRegExp(indentExpressionKeywordsArray);\nvar dedentKeywordsArray = [\"end\", \"else\", \"elsif\", \"rescue\", \"ensure\"];\nvar dedentKeywords = wordRegExp(dedentKeywordsArray);\nvar dedentPunctualsArray = [\"\\\\)\", \"\\\\}\", \"\\\\]\"];\nvar dedentPunctuals = new RegExp(\"^(?:\" + dedentPunctualsArray.join(\"|\") + \")$\");\nvar nextTokenizer = {\n  \"def\": tokenFollowIdent,\n  \"fun\": tokenFollowIdent,\n  \"macro\": tokenMacroDef,\n  \"class\": tokenFollowType,\n  \"module\": tokenFollowType,\n  \"struct\": tokenFollowType,\n  \"lib\": tokenFollowType,\n  \"enum\": tokenFollowType,\n  \"union\": tokenFollowType\n};\nvar matching = {\n  \"[\": \"]\",\n  \"{\": \"}\",\n  \"(\": \")\",\n  \"<\": \">\"\n};\nfunction tokenBase(stream, state) {\n  if (stream.eatSpace()) {\n    return null;\n  }\n\n  // Macros\n  if (state.lastToken != \"\\\\\" && stream.match(\"{%\", false)) {\n    return chain(tokenMacro(\"%\", \"%\"), stream, state);\n  }\n  if (state.lastToken != \"\\\\\" && stream.match(\"{{\", false)) {\n    return chain(tokenMacro(\"{\", \"}\"), stream, state);\n  }\n\n  // Comments\n  if (stream.peek() == \"#\") {\n    stream.skipToEnd();\n    return \"comment\";\n  }\n\n  // Variables and keywords\n  var matched;\n  if (stream.match(idents)) {\n    stream.eat(/[?!]/);\n    matched = stream.current();\n    if (stream.eat(\":\")) {\n      return \"atom\";\n    } else if (state.lastToken == \".\") {\n      return \"property\";\n    } else if (keywords.test(matched)) {\n      if (indentKeywords.test(matched)) {\n        if (!(matched == \"fun\" && state.blocks.indexOf(\"lib\") >= 0) && !(matched == \"def\" && state.lastToken == \"abstract\")) {\n          state.blocks.push(matched);\n          state.currentIndent += 1;\n        }\n      } else if ((state.lastStyle == \"operator\" || !state.lastStyle) && indentExpressionKeywords.test(matched)) {\n        state.blocks.push(matched);\n        state.currentIndent += 1;\n      } else if (matched == \"end\") {\n        state.blocks.pop();\n        state.currentIndent -= 1;\n      }\n      if (nextTokenizer.hasOwnProperty(matched)) {\n        state.tokenize.push(nextTokenizer[matched]);\n      }\n      return \"keyword\";\n    } else if (atomWords.test(matched)) {\n      return \"atom\";\n    }\n    return \"variable\";\n  }\n\n  // Class variables and instance variables\n  // or attributes\n  if (stream.eat(\"@\")) {\n    if (stream.peek() == \"[\") {\n      return chain(tokenNest(\"[\", \"]\", \"meta\"), stream, state);\n    }\n    stream.eat(\"@\");\n    stream.match(idents) || stream.match(types);\n    return \"propertyName\";\n  }\n\n  // Constants and types\n  if (stream.match(types)) {\n    return \"tag\";\n  }\n\n  // Symbols or ':' operator\n  if (stream.eat(\":\")) {\n    if (stream.eat(\"\\\"\")) {\n      return chain(tokenQuote(\"\\\"\", \"atom\", false), stream, state);\n    } else if (stream.match(idents) || stream.match(types) || stream.match(operators) || stream.match(conditionalOperators) || stream.match(indexingOperators)) {\n      return \"atom\";\n    }\n    stream.eat(\":\");\n    return \"operator\";\n  }\n\n  // Strings\n  if (stream.eat(\"\\\"\")) {\n    return chain(tokenQuote(\"\\\"\", \"string\", true), stream, state);\n  }\n\n  // Strings or regexps or macro variables or '%' operator\n  if (stream.peek() == \"%\") {\n    var style = \"string\";\n    var embed = true;\n    var delim;\n    if (stream.match(\"%r\")) {\n      // Regexps\n      style = \"string.special\";\n      delim = stream.next();\n    } else if (stream.match(\"%w\")) {\n      embed = false;\n      delim = stream.next();\n    } else if (stream.match(\"%q\")) {\n      embed = false;\n      delim = stream.next();\n    } else {\n      if (delim = stream.match(/^%([^\\w\\s=])/)) {\n        delim = delim[1];\n      } else if (stream.match(/^%[a-zA-Z_\\u009F-\\uFFFF][\\w\\u009F-\\uFFFF]*/)) {\n        // Macro variables\n        return \"meta\";\n      } else if (stream.eat('%')) {\n        // '%' operator\n        return \"operator\";\n      }\n    }\n    if (matching.hasOwnProperty(delim)) {\n      delim = matching[delim];\n    }\n    return chain(tokenQuote(delim, style, embed), stream, state);\n  }\n\n  // Here Docs\n  if (matched = stream.match(/^<<-('?)([A-Z]\\w*)\\1/)) {\n    return chain(tokenHereDoc(matched[2], !matched[1]), stream, state);\n  }\n\n  // Characters\n  if (stream.eat(\"'\")) {\n    stream.match(/^(?:[^']|\\\\(?:[befnrtv0'\"]|[0-7]{3}|u(?:[0-9a-fA-F]{4}|\\{[0-9a-fA-F]{1,6}\\})))/);\n    stream.eat(\"'\");\n    return \"atom\";\n  }\n\n  // Numbers\n  if (stream.eat(\"0\")) {\n    if (stream.eat(\"x\")) {\n      stream.match(/^[0-9a-fA-F_]+/);\n    } else if (stream.eat(\"o\")) {\n      stream.match(/^[0-7_]+/);\n    } else if (stream.eat(\"b\")) {\n      stream.match(/^[01_]+/);\n    }\n    return \"number\";\n  }\n  if (stream.eat(/^\\d/)) {\n    stream.match(/^[\\d_]*(?:\\.[\\d_]+)?(?:[eE][+-]?\\d+)?/);\n    return \"number\";\n  }\n\n  // Operators\n  if (stream.match(operators)) {\n    stream.eat(\"=\"); // Operators can follow assign symbol.\n    return \"operator\";\n  }\n  if (stream.match(conditionalOperators) || stream.match(anotherOperators)) {\n    return \"operator\";\n  }\n\n  // Parens and braces\n  if (matched = stream.match(/[({[]/, false)) {\n    matched = matched[0];\n    return chain(tokenNest(matched, matching[matched], null), stream, state);\n  }\n\n  // Escapes\n  if (stream.eat(\"\\\\\")) {\n    stream.next();\n    return \"meta\";\n  }\n  stream.next();\n  return null;\n}\nfunction tokenNest(begin, end, style, started) {\n  return function (stream, state) {\n    if (!started && stream.match(begin)) {\n      state.tokenize[state.tokenize.length - 1] = tokenNest(begin, end, style, true);\n      state.currentIndent += 1;\n      return style;\n    }\n    var nextStyle = tokenBase(stream, state);\n    if (stream.current() === end) {\n      state.tokenize.pop();\n      state.currentIndent -= 1;\n      nextStyle = style;\n    }\n    return nextStyle;\n  };\n}\nfunction tokenMacro(begin, end, started) {\n  return function (stream, state) {\n    if (!started && stream.match(\"{\" + begin)) {\n      state.currentIndent += 1;\n      state.tokenize[state.tokenize.length - 1] = tokenMacro(begin, end, true);\n      return \"meta\";\n    }\n    if (stream.match(end + \"}\")) {\n      state.currentIndent -= 1;\n      state.tokenize.pop();\n      return \"meta\";\n    }\n    return tokenBase(stream, state);\n  };\n}\nfunction tokenMacroDef(stream, state) {\n  if (stream.eatSpace()) {\n    return null;\n  }\n  var matched;\n  if (matched = stream.match(idents)) {\n    if (matched == \"def\") {\n      return \"keyword\";\n    }\n    stream.eat(/[?!]/);\n  }\n  state.tokenize.pop();\n  return \"def\";\n}\nfunction tokenFollowIdent(stream, state) {\n  if (stream.eatSpace()) {\n    return null;\n  }\n  if (stream.match(idents)) {\n    stream.eat(/[!?]/);\n  } else {\n    stream.match(operators) || stream.match(conditionalOperators) || stream.match(indexingOperators);\n  }\n  state.tokenize.pop();\n  return \"def\";\n}\nfunction tokenFollowType(stream, state) {\n  if (stream.eatSpace()) {\n    return null;\n  }\n  stream.match(types);\n  state.tokenize.pop();\n  return \"def\";\n}\nfunction tokenQuote(end, style, embed) {\n  return function (stream, state) {\n    var escaped = false;\n    while (stream.peek()) {\n      if (!escaped) {\n        if (stream.match(\"{%\", false)) {\n          state.tokenize.push(tokenMacro(\"%\", \"%\"));\n          return style;\n        }\n        if (stream.match(\"{{\", false)) {\n          state.tokenize.push(tokenMacro(\"{\", \"}\"));\n          return style;\n        }\n        if (embed && stream.match(\"#{\", false)) {\n          state.tokenize.push(tokenNest(\"#{\", \"}\", \"meta\"));\n          return style;\n        }\n        var ch = stream.next();\n        if (ch == end) {\n          state.tokenize.pop();\n          return style;\n        }\n        escaped = embed && ch == \"\\\\\";\n      } else {\n        stream.next();\n        escaped = false;\n      }\n    }\n    return style;\n  };\n}\nfunction tokenHereDoc(phrase, embed) {\n  return function (stream, state) {\n    if (stream.sol()) {\n      stream.eatSpace();\n      if (stream.match(phrase)) {\n        state.tokenize.pop();\n        return \"string\";\n      }\n    }\n    var escaped = false;\n    while (stream.peek()) {\n      if (!escaped) {\n        if (stream.match(\"{%\", false)) {\n          state.tokenize.push(tokenMacro(\"%\", \"%\"));\n          return \"string\";\n        }\n        if (stream.match(\"{{\", false)) {\n          state.tokenize.push(tokenMacro(\"{\", \"}\"));\n          return \"string\";\n        }\n        if (embed && stream.match(\"#{\", false)) {\n          state.tokenize.push(tokenNest(\"#{\", \"}\", \"meta\"));\n          return \"string\";\n        }\n        escaped = embed && stream.next() == \"\\\\\";\n      } else {\n        stream.next();\n        escaped = false;\n      }\n    }\n    return \"string\";\n  };\n}\nexport var crystal = {\n  name: \"crystal\",\n  startState: function startState() {\n    return {\n      tokenize: [tokenBase],\n      currentIndent: 0,\n      lastToken: null,\n      lastStyle: null,\n      blocks: []\n    };\n  },\n  token: function token(stream, state) {\n    var style = state.tokenize[state.tokenize.length - 1](stream, state);\n    var token = stream.current();\n    if (style && style != \"comment\") {\n      state.lastToken = token;\n      state.lastStyle = style;\n    }\n    return style;\n  },\n  indent: function indent(state, textAfter, cx) {\n    textAfter = textAfter.replace(/^\\s*(?:\\{%)?\\s*|\\s*(?:%\\})?\\s*$/g, \"\");\n    if (dedentKeywords.test(textAfter) || dedentPunctuals.test(textAfter)) {\n      return cx.unit * (state.currentIndent - 1);\n    }\n    return cx.unit * state.currentIndent;\n  },\n  languageData: {\n    indentOnInput: wordRegExp(dedentPunctualsArray.concat(dedentKeywordsArray), true),\n    commentTokens: {\n      line: \"#\"\n    }\n  }\n};"],"sourceRoot":""}