{"version":3,"sources":["D:/react_app/app_1/node_modules/@codemirror/legacy-modes/mode/coffeescript.js"],"names":["__webpack_require__","r","__webpack_exports__","d","coffeeScript","ERRORCLASS","wordRegexp","words","RegExp","join","operators","delimiters","identifiers","atProp","wordOperators","indentKeywords","keywords","concat","stringPrefixes","regexPrefixes","constants","tokenBase","stream","state","sol","scope","align","scopeOffset","offset","eatSpace","lineOffset","indentation","type","dedent","ch","peek","match","skipToEnd","tokenize","longComment","floatLiteral","backUp","intLiteral","tokenFactory","current","prop","next","delimiter","singleline","outclass","eol","eatWhile","eat","indent","arguments","length","undefined","alignOffset","prev","indentUnit","column","_indent","matched","name","startState","token","fillAlign","style","delimiter_index","indexOf","slice","exec","tokenLexer","text","closer","charAt","closes","languageData","commentTokens","line"],"mappings":"2FAAAA,EAAAC,EAAAC,GAAAF,EAAAG,EAAAD,EAAA,iCAAAE,IAAA,IAAAC,EAAA,QACA,SAAAC,EAAAC,GACA,WAAAC,OAAA,MAAAD,EAAAE,KAAA,gBAEA,IAAAC,EAAA,mHACAC,EAAA,gCACAC,EAAA,4BACAC,EAAA,6BACAC,EAAAR,EAAA,2DACAS,EAAA,qFAEAC,EAAAV,EAAAS,EAAAE,OADA,iIAEAF,EAAAT,EAAAS,GACA,IAAAG,EAAA,sBACAC,EAAA,cAEAC,EAAAd,EADA,4EAIA,SAAAe,EAAAC,EAAAC,GAEA,GAAAD,EAAAE,MAAA,CACA,OAAAD,EAAAE,MAAAC,QAAAH,EAAAE,MAAAC,OAAA,GACA,IAAAC,EAAAJ,EAAAE,MAAAG,OACA,GAAAN,EAAAO,WAAA,CACA,IAAAC,EAAAR,EAAAS,cACA,OAAAD,EAAAH,GAAA,UAAAJ,EAAAE,MAAAO,KACA,SACOF,EAAAH,EACP,SAEA,KAEAA,EAAA,GACAM,EAAAX,EAAAC,GAIA,GAAAD,EAAAO,WACA,YAEA,IAAAK,EAAAZ,EAAAa,OAGA,GAAAb,EAAAc,MAAA,QAEA,OADAd,EAAAe,YACA,UAIA,GAAAf,EAAAc,MAAA,OAEA,OADAb,EAAAe,SAAAC,EACAhB,EAAAe,SAAAhB,EAAAC,GAIA,SAAAW,EAEA,OADAZ,EAAAe,YACA,UAIA,GAAAf,EAAAc,MAAA,kBACA,IAAAI,GAAA,EAWA,GATAlB,EAAAc,MAAA,gCACAI,GAAA,GAEAlB,EAAAc,MAAA,iBACAI,GAAA,GAEAlB,EAAAc,MAAA,cACAI,GAAA,GAEAA,EAKA,MAHA,KAAAlB,EAAAa,QACAb,EAAAmB,OAAA,GAEA,SAGA,IAAAC,GAAA,EAaA,GAXApB,EAAAc,MAAA,qBACAM,GAAA,GAGApB,EAAAc,MAAA,+BACAM,GAAA,GAGApB,EAAAc,MAAA,oBACAM,GAAA,GAEAA,EACA,eAKA,GAAApB,EAAAc,MAAAlB,GAEA,OADAK,EAAAe,SAAAK,EAAArB,EAAAsB,WAAA,YACArB,EAAAe,SAAAhB,EAAAC,GAGA,GAAAD,EAAAc,MAAAjB,GAAA,CACA,QAAAG,EAAAsB,WAAAtB,EAAAc,MAAA,YAGA,OADAb,EAAAe,SAAAK,EAAArB,EAAAsB,WAAA,oBACArB,EAAAe,SAAAhB,EAAAC,GAEAD,EAAAmB,OAAA,GAKA,OAAAnB,EAAAc,MAAA1B,IAAAY,EAAAc,MAAAtB,GACA,WAEAQ,EAAAc,MAAAzB,GACA,cAEAW,EAAAc,MAAAhB,GACA,OAEAE,EAAAc,MAAAvB,IAAAU,EAAAsB,MAAAvB,EAAAc,MAAAxB,GACA,WAEAU,EAAAc,MAAApB,GACA,UAEAM,EAAAc,MAAAxB,GACA,YAIAU,EAAAwB,OACAzC,GAEA,SAAAsC,EAAAI,EAAAC,EAAAC,GACA,gBAAA3B,EAAAC,GACA,MAAAD,EAAA4B,OAEA,GADA5B,EAAA6B,SAAA,aACA7B,EAAA8B,IAAA,OAEA,GADA9B,EAAAwB,OACAE,GAAA1B,EAAA4B,MACA,OAAAD,MAEO,IAAA3B,EAAAc,MAAAW,GAEP,OADAxB,EAAAe,SAAAjB,EACA4B,EAEA3B,EAAA8B,IAAA,UAMA,OAHAJ,IACAzB,EAAAe,SAAAjB,GAEA4B,GAGA,SAAAV,EAAAjB,EAAAC,GACA,MAAAD,EAAA4B,OAAA,CAEA,GADA5B,EAAA6B,SAAA,QACA7B,EAAAc,MAAA,QACAb,EAAAe,SAAAjB,EACA,MAEAC,EAAA6B,SAAA,KAEA,gBAEA,SAAAE,EAAA/B,EAAAC,GAKA,IAJA,IAAAS,EAAAsB,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,YACA1B,EAAA,EACAF,GAAA,EACA+B,EAAA,KACAhC,EAAAF,EAAAE,MAA+BA,EAAOA,IAAAiC,KACtC,cAAAjC,EAAAO,MAAA,KAAAP,EAAAO,KAAmD,CACnDJ,EAAAH,EAAAG,OAAAN,EAAAqC,WACA,MAGA,WAAA3B,GACAN,EAAA,KACA+B,EAAAnC,EAAAsC,SAAAtC,EAAAsB,UAAAW,QACGhC,EAAAE,MAAAC,QACHH,EAAAE,MAAAC,OAAA,GAEAH,EAAAE,MAAA,CACAG,SACAI,OACA0B,KAAAnC,EAAAE,MACAC,QACA+B,eAGA,SAAAxB,EAAAX,EAAAC,GACA,GAAAA,EAAAE,MAAAiC,KAAA,CACA,cAAAnC,EAAAE,MAAAO,KAAA,CAGA,IAFA,IAAA6B,EAAAvC,EAAAS,cACA+B,GAAA,EACArC,EAAAF,EAAAE,MAAiCA,EAAOA,IAAAiC,KACxC,GAAAG,IAAApC,EAAAG,OAAA,CACAkC,GAAA,EACA,MAGA,IAAAA,EACA,SAEA,KAAAvC,EAAAE,MAAAiC,MAAAnC,EAAAE,MAAAG,SAAAiC,GACAtC,EAAAE,MAAAF,EAAAE,MAAAiC,KAEA,SAGA,OADAnC,EAAAE,MAAAF,EAAAE,MAAAiC,MACA,GAwCO,IAAAtD,EAAA,CACP2D,KAAA,eACAC,WAAA,WACA,OACA1B,SAAAjB,EACAI,MAAA,CACAG,OAAA,EACAI,KAAA,SACA0B,KAAA,KACAhC,OAAA,GAEAmB,MAAA,EACAZ,OAAA,IAGAgC,MAAA,SAAA3C,EAAAC,GACA,IAAA2C,EAAA,OAAA3C,EAAAE,MAAAC,OAAAH,EAAAE,MACAyC,GAAA5C,EAAAE,QAAA0C,EAAAxC,OAAA,GACA,IAAAyC,EAvDA,SAAA7C,EAAAC,GACA,IAAA4C,EAAA5C,EAAAe,SAAAhB,EAAAC,GACAqB,EAAAtB,EAAAsB,UAGA,WAAAA,IACArB,EAAAU,QAAA,KAEA,OAAAW,GAAA,OAAAA,IAAAtB,EAAA4B,OAAA,WAAAiB,IACAd,EAAA/B,EAAAC,GAEA,IAAA6C,EAAA,MAA4BC,QAAAzB,GAU5B,IATA,IAAAwB,GACAf,EAAA/B,EAAAC,EAAA,MAA8B+C,MAAAF,IAAA,IAE9BrD,EAAAwD,KAAA3B,IACAS,EAAA/B,EAAAC,GAEA,QAAAqB,GACAX,EAAAX,EAAAC,GAEA,WAAA4C,GACAlC,EAAAX,EAAAC,GACA,OAAAlB,EAIA,SADA+D,EAAA,MAAwBC,QAAAzB,IACxB,CACA,eAAArB,EAAAE,MAAAO,MAAAT,EAAAE,MAAAiC,MAAAnC,EAAAE,MAAAF,EAAAE,MAAAiC,KACAnC,EAAAE,MAAAO,MAAAY,IAAArB,EAAAE,MAAAF,EAAAE,MAAAiC,MAMA,OAJAnC,EAAAU,QAAAX,EAAA4B,QACA,UAAA3B,EAAAE,MAAAO,MAAAT,EAAAE,MAAAiC,OAAAnC,EAAAE,MAAAF,EAAAE,MAAAiC,MACAnC,EAAAU,QAAA,GAEA,UAAAkC,GAAA,UAAAA,EAAA,KAAAA,EAoBAK,CAAAlD,EAAAC,GAKA,OAJA4C,GAAA,WAAAA,IACAD,MAAAxC,OAAA,GACAH,EAAAsB,KAAA,eAAAsB,GAAA,KAAA7C,EAAAsB,WAEAuB,GAEAd,OAAA,SAAA9B,EAAAkD,GACA,GAAAlD,EAAAe,UAAAjB,EAAA,SACA,IAAAI,EAAAF,EAAAE,MACAiD,EAAAD,GAAA,MAA6BJ,QAAAI,EAAAE,OAAA,OAC7B,GAAAD,EAAA,eAAAjD,EAAAO,MAAAP,EAAAiC,MAAAjC,IAAAiC,KACA,IAAAkB,EAAAF,GAAAjD,EAAAO,OAAAyC,EAAAE,OAAA,GACA,OAAAlD,EAAAC,MAAAD,EAAAgC,aAAAmB,EAAA,MAAiEA,EAAAnD,EAAAiC,KAAAjC,GAAAG,QAEjEiD,aAAA,CACAC,cAAA,CACAC,KAAA","file":"static/js/31.facbe07a.chunk.js","sourcesContent":["var ERRORCLASS = \"error\";\nfunction wordRegexp(words) {\n  return new RegExp(\"^((\" + words.join(\")|(\") + \"))\\\\b\");\n}\nvar operators = /^(?:->|=>|\\+[+=]?|-[\\-=]?|\\*[\\*=]?|\\/[\\/=]?|[=!]=|<[><]?=?|>>?=?|%=?|&=?|\\|=?|\\^=?|\\~|!|\\?|(or|and|\\|\\||&&|\\?)=)/;\nvar delimiters = /^(?:[()\\[\\]{},:`=;]|\\.\\.?\\.?)/;\nvar identifiers = /^[_A-Za-z$][_A-Za-z$0-9]*/;\nvar atProp = /^@[_A-Za-z$][_A-Za-z$0-9]*/;\nvar wordOperators = wordRegexp([\"and\", \"or\", \"not\", \"is\", \"isnt\", \"in\", \"instanceof\", \"typeof\"]);\nvar indentKeywords = [\"for\", \"while\", \"loop\", \"if\", \"unless\", \"else\", \"switch\", \"try\", \"catch\", \"finally\", \"class\"];\nvar commonKeywords = [\"break\", \"by\", \"continue\", \"debugger\", \"delete\", \"do\", \"in\", \"of\", \"new\", \"return\", \"then\", \"this\", \"@\", \"throw\", \"when\", \"until\", \"extends\"];\nvar keywords = wordRegexp(indentKeywords.concat(commonKeywords));\nindentKeywords = wordRegexp(indentKeywords);\nvar stringPrefixes = /^('{3}|\\\"{3}|['\\\"])/;\nvar regexPrefixes = /^(\\/{3}|\\/)/;\nvar commonConstants = [\"Infinity\", \"NaN\", \"undefined\", \"null\", \"true\", \"false\", \"on\", \"off\", \"yes\", \"no\"];\nvar constants = wordRegexp(commonConstants);\n\n// Tokenizers\nfunction tokenBase(stream, state) {\n  // Handle scope changes\n  if (stream.sol()) {\n    if (state.scope.align === null) state.scope.align = false;\n    var scopeOffset = state.scope.offset;\n    if (stream.eatSpace()) {\n      var lineOffset = stream.indentation();\n      if (lineOffset > scopeOffset && state.scope.type == \"coffee\") {\n        return \"indent\";\n      } else if (lineOffset < scopeOffset) {\n        return \"dedent\";\n      }\n      return null;\n    } else {\n      if (scopeOffset > 0) {\n        dedent(stream, state);\n      }\n    }\n  }\n  if (stream.eatSpace()) {\n    return null;\n  }\n  var ch = stream.peek();\n\n  // Handle docco title comment (single line)\n  if (stream.match(\"####\")) {\n    stream.skipToEnd();\n    return \"comment\";\n  }\n\n  // Handle multi line comments\n  if (stream.match(\"###\")) {\n    state.tokenize = longComment;\n    return state.tokenize(stream, state);\n  }\n\n  // Single line comment\n  if (ch === \"#\") {\n    stream.skipToEnd();\n    return \"comment\";\n  }\n\n  // Handle number literals\n  if (stream.match(/^-?[0-9\\.]/, false)) {\n    var floatLiteral = false;\n    // Floats\n    if (stream.match(/^-?\\d*\\.\\d+(e[\\+\\-]?\\d+)?/i)) {\n      floatLiteral = true;\n    }\n    if (stream.match(/^-?\\d+\\.\\d*/)) {\n      floatLiteral = true;\n    }\n    if (stream.match(/^-?\\.\\d+/)) {\n      floatLiteral = true;\n    }\n    if (floatLiteral) {\n      // prevent from getting extra . on 1..\n      if (stream.peek() == \".\") {\n        stream.backUp(1);\n      }\n      return \"number\";\n    }\n    // Integers\n    var intLiteral = false;\n    // Hex\n    if (stream.match(/^-?0x[0-9a-f]+/i)) {\n      intLiteral = true;\n    }\n    // Decimal\n    if (stream.match(/^-?[1-9]\\d*(e[\\+\\-]?\\d+)?/)) {\n      intLiteral = true;\n    }\n    // Zero by itself with no other piece of number.\n    if (stream.match(/^-?0(?![\\dx])/i)) {\n      intLiteral = true;\n    }\n    if (intLiteral) {\n      return \"number\";\n    }\n  }\n\n  // Handle strings\n  if (stream.match(stringPrefixes)) {\n    state.tokenize = tokenFactory(stream.current(), false, \"string\");\n    return state.tokenize(stream, state);\n  }\n  // Handle regex literals\n  if (stream.match(regexPrefixes)) {\n    if (stream.current() != \"/\" || stream.match(/^.*\\//, false)) {\n      // prevent highlight of division\n      state.tokenize = tokenFactory(stream.current(), true, \"string.special\");\n      return state.tokenize(stream, state);\n    } else {\n      stream.backUp(1);\n    }\n  }\n\n  // Handle operators and delimiters\n  if (stream.match(operators) || stream.match(wordOperators)) {\n    return \"operator\";\n  }\n  if (stream.match(delimiters)) {\n    return \"punctuation\";\n  }\n  if (stream.match(constants)) {\n    return \"atom\";\n  }\n  if (stream.match(atProp) || state.prop && stream.match(identifiers)) {\n    return \"property\";\n  }\n  if (stream.match(keywords)) {\n    return \"keyword\";\n  }\n  if (stream.match(identifiers)) {\n    return \"variable\";\n  }\n\n  // Handle non-detected items\n  stream.next();\n  return ERRORCLASS;\n}\nfunction tokenFactory(delimiter, singleline, outclass) {\n  return function (stream, state) {\n    while (!stream.eol()) {\n      stream.eatWhile(/[^'\"\\/\\\\]/);\n      if (stream.eat(\"\\\\\")) {\n        stream.next();\n        if (singleline && stream.eol()) {\n          return outclass;\n        }\n      } else if (stream.match(delimiter)) {\n        state.tokenize = tokenBase;\n        return outclass;\n      } else {\n        stream.eat(/['\"\\/]/);\n      }\n    }\n    if (singleline) {\n      state.tokenize = tokenBase;\n    }\n    return outclass;\n  };\n}\nfunction longComment(stream, state) {\n  while (!stream.eol()) {\n    stream.eatWhile(/[^#]/);\n    if (stream.match(\"###\")) {\n      state.tokenize = tokenBase;\n      break;\n    }\n    stream.eatWhile(\"#\");\n  }\n  return \"comment\";\n}\nfunction indent(stream, state) {\n  var type = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : \"coffee\";\n  var offset = 0,\n    align = false,\n    alignOffset = null;\n  for (var scope = state.scope; scope; scope = scope.prev) {\n    if (scope.type === \"coffee\" || scope.type == \"}\") {\n      offset = scope.offset + stream.indentUnit;\n      break;\n    }\n  }\n  if (type !== \"coffee\") {\n    align = null;\n    alignOffset = stream.column() + stream.current().length;\n  } else if (state.scope.align) {\n    state.scope.align = false;\n  }\n  state.scope = {\n    offset: offset,\n    type: type,\n    prev: state.scope,\n    align: align,\n    alignOffset: alignOffset\n  };\n}\nfunction dedent(stream, state) {\n  if (!state.scope.prev) return;\n  if (state.scope.type === \"coffee\") {\n    var _indent = stream.indentation();\n    var matched = false;\n    for (var scope = state.scope; scope; scope = scope.prev) {\n      if (_indent === scope.offset) {\n        matched = true;\n        break;\n      }\n    }\n    if (!matched) {\n      return true;\n    }\n    while (state.scope.prev && state.scope.offset !== _indent) {\n      state.scope = state.scope.prev;\n    }\n    return false;\n  } else {\n    state.scope = state.scope.prev;\n    return false;\n  }\n}\nfunction tokenLexer(stream, state) {\n  var style = state.tokenize(stream, state);\n  var current = stream.current();\n\n  // Handle scope changes.\n  if (current === \"return\") {\n    state.dedent = true;\n  }\n  if ((current === \"->\" || current === \"=>\") && stream.eol() || style === \"indent\") {\n    indent(stream, state);\n  }\n  var delimiter_index = \"[({\".indexOf(current);\n  if (delimiter_index !== -1) {\n    indent(stream, state, \"])}\".slice(delimiter_index, delimiter_index + 1));\n  }\n  if (indentKeywords.exec(current)) {\n    indent(stream, state);\n  }\n  if (current == \"then\") {\n    dedent(stream, state);\n  }\n  if (style === \"dedent\") {\n    if (dedent(stream, state)) {\n      return ERRORCLASS;\n    }\n  }\n  delimiter_index = \"])}\".indexOf(current);\n  if (delimiter_index !== -1) {\n    while (state.scope.type == \"coffee\" && state.scope.prev) state.scope = state.scope.prev;\n    if (state.scope.type == current) state.scope = state.scope.prev;\n  }\n  if (state.dedent && stream.eol()) {\n    if (state.scope.type == \"coffee\" && state.scope.prev) state.scope = state.scope.prev;\n    state.dedent = false;\n  }\n  return style == \"indent\" || style == \"dedent\" ? null : style;\n}\nexport var coffeeScript = {\n  name: \"coffeescript\",\n  startState: function startState() {\n    return {\n      tokenize: tokenBase,\n      scope: {\n        offset: 0,\n        type: \"coffee\",\n        prev: null,\n        align: false\n      },\n      prop: false,\n      dedent: 0\n    };\n  },\n  token: function token(stream, state) {\n    var fillAlign = state.scope.align === null && state.scope;\n    if (fillAlign && stream.sol()) fillAlign.align = false;\n    var style = tokenLexer(stream, state);\n    if (style && style != \"comment\") {\n      if (fillAlign) fillAlign.align = true;\n      state.prop = style == \"punctuation\" && stream.current() == \".\";\n    }\n    return style;\n  },\n  indent: function indent(state, text) {\n    if (state.tokenize != tokenBase) return 0;\n    var scope = state.scope;\n    var closer = text && \"])}\".indexOf(text.charAt(0)) > -1;\n    if (closer) while (scope.type == \"coffee\" && scope.prev) scope = scope.prev;\n    var closes = closer && scope.type === text.charAt(0);\n    if (scope.align) return scope.alignOffset - (closes ? 1 : 0);else return (closes ? scope.prev : scope).offset;\n  },\n  languageData: {\n    commentTokens: {\n      line: \"#\"\n    }\n  }\n};"],"sourceRoot":""}