{"version":3,"sources":["D:/react_app/app_1/node_modules/@codemirror/legacy-modes/mode/tcl.js"],"names":["parseWords","str","obj","words","split","i","length","__webpack_require__","r","__webpack_exports__","d","tcl","keywords","functions","isOperatorChar","chain","stream","state","f","tokenize","tokenBase","beforeParams","quote","ch","next","inParams","test","eatWhile","eat","tokenComment","match","tokenUnparsed","skipToEnd","skipTo","word","current","toLowerCase","propertyIsEnumerable","escaped","end","maybeEnd","name","startState","token","eatSpace","languageData","commentTokens","line"],"mappings":"2FAAA,SAAAA,EAAAC,GAGA,IAFA,IAAAC,EAAA,GACAC,EAAAF,EAAAG,MAAA,KACAC,EAAA,EAAiBA,EAAAF,EAAAG,SAAkBD,EAAAH,EAAAC,EAAAE,KAAA,EACnC,OAAAH,EAJAK,EAAAC,EAAAC,GAAAF,EAAAG,EAAAD,EAAA,wBAAAE,IAMA,IAAAC,EAAAZ,EAAA,+zBACAa,EAAAb,EAAA,kEACAc,EAAA,qBACA,SAAAC,EAAAC,EAAAC,EAAAC,GAEA,OADAD,EAAAE,SAAAD,EACAA,EAAAF,EAAAC,GAEA,SAAAG,EAAAJ,EAAAC,GACA,IAAAI,EAAAJ,EAAAI,aACAJ,EAAAI,cAAA,EACA,IAoCAC,EApCAC,EAAAP,EAAAQ,OACA,QAAAD,GAAA,KAAAA,IAAAN,EAAAQ,SAEG,uBAAwBC,KAAAH,GAE3B,MADA,KAAAA,GAAAF,EAAAJ,EAAAQ,UAAA,EAAyD,KAAAF,IAAAN,EAAAQ,UAAA,GACzD,KACG,QAAAC,KAAAH,GAEH,OADAP,EAAAW,SAAA,UACA,SACG,QAAAJ,EACH,OAAAP,EAAAY,IAAA,KAAAb,EAAAC,EAAAC,EAAAY,GACA,KAAAN,GAAAP,EAAAc,MAAA,YAAAf,EAAAC,EAAAC,EAAAc,IACAf,EAAAgB,YACA,WACG,QAAAT,EAEH,OADAP,EAAAiB,OAAA,KACA,UACG,QAAAV,EAIH,OAHAP,EAAAW,SAAA,qBACAX,EAAAW,SAAA,KACAV,EAAAI,cAAA,EACA,UACG,GAAAP,EAAAY,KAAAH,GAEH,OADAP,EAAAW,SAAAb,GACA,UAEAE,EAAAW,SAAA,wBACA,IAAAO,EAAAlB,EAAAmB,UAAAC,cACA,OAAAxB,KAAAyB,qBAAAH,GAAA,UACArB,KAAAwB,qBAAAH,IACAjB,EAAAI,cAAA,EACA,WAEA,KA/BA,OAAAN,EAAAC,EAAAC,GAkCAK,EAlCAC,EAmCA,SAAAP,EAAAC,GAIA,IAHA,IACAO,EADAc,GAAA,EAEAC,GAAA,EACA,OAAAf,EAAAR,EAAAQ,SAAA,CACA,GAAAA,GAAAF,IAAAgB,EAAA,CACAC,GAAA,EACA,MAEAD,MAAA,MAAAd,EAGA,OADAe,IAAAtB,EAAAE,SAAAC,GACA,YAGA,SAAAS,EAAAb,EAAAC,GAGA,IAFA,IACAM,EADAiB,GAAA,EAEAjB,EAAAP,EAAAQ,QAAA,CACA,QAAAD,GAAAiB,EAAA,CACAvB,EAAAE,SAAAC,EACA,MAEAoB,EAAA,KAAAjB,EAEA,gBAEA,SAAAQ,EAAAf,EAAAC,GAGA,IAFA,IACAM,EADAiB,EAAA,EAEAjB,EAAAP,EAAAQ,QAAA,CACA,QAAAD,GAAA,GAAAiB,EAAA,CACAvB,EAAAE,SAAAC,EACA,MAEA,KAAAG,EAAAiB,IAA8B,KAAAjB,IAAAiB,EAAA,GAE9B,aAEO,IAAA7B,EAAA,CACP8B,KAAA,MACAC,WAAA,WACA,OACAvB,SAAAC,EACAC,cAAA,EACAI,UAAA,IAGAkB,MAAA,SAAA3B,EAAAC,GACA,OAAAD,EAAA4B,WAAA,KACA3B,EAAAE,SAAAH,EAAAC,IAEA4B,aAAA,CACAC,cAAA,CACAC,KAAA","file":"static/js/91.2565f2f2.chunk.js","sourcesContent":["function parseWords(str) {\n  var obj = {},\n    words = str.split(\" \");\n  for (var i = 0; i < words.length; ++i) obj[words[i]] = true;\n  return obj;\n}\nvar keywords = parseWords(\"Tcl safe after append array auto_execok auto_import auto_load \" + \"auto_mkindex auto_mkindex_old auto_qualify auto_reset bgerror \" + \"binary break catch cd close concat continue dde eof encoding error \" + \"eval exec exit expr fblocked fconfigure fcopy file fileevent filename \" + \"filename flush for foreach format gets glob global history http if \" + \"incr info interp join lappend lindex linsert list llength load lrange \" + \"lreplace lsearch lset lsort memory msgcat namespace open package parray \" + \"pid pkg::create pkg_mkIndex proc puts pwd re_syntax read regex regexp \" + \"registry regsub rename resource return scan seek set socket source split \" + \"string subst switch tcl_endOfWord tcl_findLibrary tcl_startOfNextWord \" + \"tcl_wordBreakAfter tcl_startOfPreviousWord tcl_wordBreakBefore tcltest \" + \"tclvars tell time trace unknown unset update uplevel upvar variable \" + \"vwait\");\nvar functions = parseWords(\"if elseif else and not or eq ne in ni for foreach while switch\");\nvar isOperatorChar = /[+\\-*&%=<>!?^\\/\\|]/;\nfunction chain(stream, state, f) {\n  state.tokenize = f;\n  return f(stream, state);\n}\nfunction tokenBase(stream, state) {\n  var beforeParams = state.beforeParams;\n  state.beforeParams = false;\n  var ch = stream.next();\n  if ((ch == '\"' || ch == \"'\") && state.inParams) {\n    return chain(stream, state, tokenString(ch));\n  } else if (/[\\[\\]{}\\(\\),;\\.]/.test(ch)) {\n    if (ch == \"(\" && beforeParams) state.inParams = true;else if (ch == \")\") state.inParams = false;\n    return null;\n  } else if (/\\d/.test(ch)) {\n    stream.eatWhile(/[\\w\\.]/);\n    return \"number\";\n  } else if (ch == \"#\") {\n    if (stream.eat(\"*\")) return chain(stream, state, tokenComment);\n    if (ch == \"#\" && stream.match(/ *\\[ *\\[/)) return chain(stream, state, tokenUnparsed);\n    stream.skipToEnd();\n    return \"comment\";\n  } else if (ch == '\"') {\n    stream.skipTo(/\"/);\n    return \"comment\";\n  } else if (ch == \"$\") {\n    stream.eatWhile(/[$_a-z0-9A-Z\\.{:]/);\n    stream.eatWhile(/}/);\n    state.beforeParams = true;\n    return \"builtin\";\n  } else if (isOperatorChar.test(ch)) {\n    stream.eatWhile(isOperatorChar);\n    return \"comment\";\n  } else {\n    stream.eatWhile(/[\\w\\$_{}\\xa1-\\uffff]/);\n    var word = stream.current().toLowerCase();\n    if (keywords && keywords.propertyIsEnumerable(word)) return \"keyword\";\n    if (functions && functions.propertyIsEnumerable(word)) {\n      state.beforeParams = true;\n      return \"keyword\";\n    }\n    return null;\n  }\n}\nfunction tokenString(quote) {\n  return function (stream, state) {\n    var escaped = false,\n      next,\n      end = false;\n    while ((next = stream.next()) != null) {\n      if (next == quote && !escaped) {\n        end = true;\n        break;\n      }\n      escaped = !escaped && next == \"\\\\\";\n    }\n    if (end) state.tokenize = tokenBase;\n    return \"string\";\n  };\n}\nfunction tokenComment(stream, state) {\n  var maybeEnd = false,\n    ch;\n  while (ch = stream.next()) {\n    if (ch == \"#\" && maybeEnd) {\n      state.tokenize = tokenBase;\n      break;\n    }\n    maybeEnd = ch == \"*\";\n  }\n  return \"comment\";\n}\nfunction tokenUnparsed(stream, state) {\n  var maybeEnd = 0,\n    ch;\n  while (ch = stream.next()) {\n    if (ch == \"#\" && maybeEnd == 2) {\n      state.tokenize = tokenBase;\n      break;\n    }\n    if (ch == \"]\") maybeEnd++;else if (ch != \" \") maybeEnd = 0;\n  }\n  return \"meta\";\n}\nexport var tcl = {\n  name: \"tcl\",\n  startState: function startState() {\n    return {\n      tokenize: tokenBase,\n      beforeParams: false,\n      inParams: false\n    };\n  },\n  token: function token(stream, state) {\n    if (stream.eatSpace()) return null;\n    return state.tokenize(stream, state);\n  },\n  languageData: {\n    commentTokens: {\n      line: \"#\"\n    }\n  }\n};"],"sourceRoot":""}