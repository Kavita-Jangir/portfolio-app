{"version":3,"sources":["D:/react_app/app_1/node_modules/@codemirror/legacy-modes/mode/swift.js"],"names":["wordSet","words","set","i","length","__webpack_require__","r","__webpack_exports__","d","swift","keywords","definingKeywords","atoms","types","operators","punc","binary","octal","hexadecimal","decimal","identifier","property","instruction","attribute","tokenBase","stream","state","prev","sol","indented","indentation","eatSpace","stringMatch","ch","peek","match","skipToEnd","tokenize","push","tokenComment","indexOf","next","openQuote","singleLine","escaped","tokenUntilClosingParen","pop","bind","ident","current","hasOwnProperty","depth","inner","backUp","eat","Context","align","this","name","startState","context","token","style","bracket","exec","column","indent","textAfter","iCx","cx","closing","test","unit","languageData","indentOnInput","commentTokens","line","block","open","close","closeBrackets","brackets"],"mappings":"2FAAA,SAAAA,EAAAC,GAEA,IADA,IAAAC,EAAA,GACAC,EAAA,EAAiBA,EAAAF,EAAAG,OAAkBD,IAAAD,EAAAD,EAAAE,KAAA,EACnC,OAAAD,EAHAG,EAAAC,EAAAC,GAAAF,EAAAG,EAAAD,EAAA,0BAAAE,IAKA,IAAAC,EAAAV,EAAA,w2BACAW,EAAAX,EAAA,yHACAY,EAAAZ,EAAA,2CACAa,EAAAb,EAAA,6KACAc,EAAA,iBACAC,EAAA,aACAC,EAAA,mBACAC,EAAA,qBACAC,EAAA,gFACAC,EAAA,kDACAC,EAAA,uCACAC,EAAA,6CACAC,EAAA,eACAC,EAAA,4CAGA,SAAAC,EAAAC,EAAAC,EAAAC,GAEA,GADAF,EAAAG,QAAAF,EAAAG,SAAAJ,EAAAK,eACAL,EAAAM,WAAA,YACA,IA2BAC,EA3BAC,EAAAR,EAAAS,OACA,QAAAD,EAAA,CACA,GAAAR,EAAAU,MAAA,MAEA,OADAV,EAAAW,YACA,UAEA,GAAAX,EAAAU,MAAA,MAEA,OADAT,EAAAW,SAAAC,KAAAC,GACAA,EAAAd,EAAAC,GAGA,GAAAD,EAAAU,MAAAb,GAAA,gBACA,GAAAG,EAAAU,MAAAZ,GAAA,kBACA,GAAAE,EAAAU,MAAAnB,GAAA,eACA,GAAAS,EAAAU,MAAAlB,GAAA,eACA,GAAAQ,EAAAU,MAAAjB,GAAA,eACA,GAAAO,EAAAU,MAAAhB,GAAA,eACA,GAAAM,EAAAU,MAAAd,GAAA,iBACA,GAAAP,EAAA0B,QAAAP,IAAA,EAEA,OADAR,EAAAgB,OACA,WAEA,GAAA1B,EAAAyB,QAAAP,IAAA,EAGA,OAFAR,EAAAgB,OACAhB,EAAAU,MAAA,MACA,cAGA,GAAAH,EAAAP,EAAAU,MAAA,cACA,IAAAE,EAkCA,SAAAK,EAAAjB,EAAAC,GACA,IACAO,EADAU,EAAA,GAAAD,EAAAtC,OAEAwC,GAAA,EACA,KAAAX,EAAAR,EAAAS,QACA,GAAAU,EAAA,CAEA,GADAnB,EAAAgB,OACA,KAAAR,EAEA,OADAP,EAAAW,SAAAC,KAAAO,KACA,SAEAD,GAAA,MACK,IAAAnB,EAAAU,MAAAO,GAEL,OADAhB,EAAAW,SAAAS,MACA,SAEArB,EAAAgB,OACAG,EAAA,MAAAX,EAGAU,GACAjB,EAAAW,SAAAS,MAEA,gBAzDAC,KAAA,KAAAf,EAAA,IAEA,OADAN,EAAAW,SAAAC,KAAAD,GACAA,EAAAZ,EAAAC,GAEA,GAAAD,EAAAU,MAAAf,GAAA,CACA,IAAA4B,EAAAvB,EAAAwB,UACA,OAAApC,EAAAqC,eAAAF,GAAA,OACApC,EAAAsC,eAAAF,GAAA,OACAtC,EAAAwC,eAAAF,IACArC,EAAAuC,eAAAF,KAAAtB,EAAAC,KAAA,UACA,WAEA,UAAAA,EAAA,MACA,WAGA,OADAF,EAAAgB,OACA,KAEA,SAAAI,IACA,IAAAM,EAAA,EACA,gBAAA1B,EAAAC,EAAAC,GACA,IAAAyB,EAAA5B,EAAAC,EAAAC,EAAAC,GACA,kBAAAyB,EACA,QAAA3B,EAAAwB,YAAAE,OAA2C,QAAA1B,EAAAwB,UAAA,CAC3C,MAAAE,EAGA,OAFA1B,EAAA4B,OAAA,GACA3B,EAAAW,SAAAS,MACApB,EAAAW,SAAAX,EAAAW,SAAAjC,OAAA,GAAAqB,EAAAC,KACSyB,EAGT,OAAAC,GA4BA,SAAAb,EAAAd,EAAAC,GAEA,IADA,IAAAO,EACAA,EAAAR,EAAAgB,QACA,SAAAR,GAAAR,EAAA6B,IAAA,KACA5B,EAAAW,SAAAC,KAAAC,QACK,SAAAN,GAAAR,EAAA6B,IAAA,MACL5B,EAAAW,SAAAS,MACA,MAGA,gBAEA,SAAAS,EAAA5B,EAAA6B,EAAA3B,GACA4B,KAAA9B,OACA8B,KAAAD,QACAC,KAAA5B,WAYO,IAAApB,EAAA,CACPiD,KAAA,QACAC,WAAA,WACA,OACAhC,KAAA,KACAiC,QAAA,KACA/B,SAAA,EACAQ,SAAA,KAGAwB,MAAA,SAAApC,EAAAC,GACA,IAAAC,EAAAD,EAAAC,KACAD,EAAAC,KAAA,KACA,IACAmC,GADApC,EAAAW,SAAAX,EAAAW,SAAAjC,OAAA,IAAAoB,GACAC,EAAAC,EAAAC,GAEA,GADAmC,GAAA,WAAAA,EAAwDpC,EAAAC,OAAAD,EAAAC,KAAAmC,GAAxDpC,EAAAC,OACA,eAAAmC,EAAA,CACA,IAAAC,EAAA,sBAAsCC,KAAAvC,EAAAwB,WACtCc,MAAA,GAxBA,SAAArC,GACAA,EAAAkC,UACAlC,EAAAG,SAAAH,EAAAkC,QAAA/B,SACAH,EAAAkC,QAAAlC,EAAAkC,QAAAjC,OAPA,SAAAD,EAAAD,GACA,IAAA+B,EAAA/B,EAAAU,MAAA,2BAA+C,QAAAV,EAAAwC,SAAA,EAC/CvC,EAAAkC,QAAA,IAAAL,EAAA7B,EAAAkC,QAAAJ,EAAA9B,EAAAG,YA0BAH,EAAAD,GAEA,OAAAqC,GAEAI,OAAA,SAAAxC,EAAAyC,EAAAC,GACA,IAAAC,EAAA3C,EAAAkC,QACA,IAAAS,EAAA,SACA,IAAAC,EAAA,YAAyBC,KAAAJ,GACzB,aAAAE,EAAAb,MAAAa,EAAAb,OAAAc,EAAA,KACAD,EAAAxC,UAAAyC,EAAA,EAAAF,EAAAI,OAEAC,aAAA,CACAC,cAAA,gBACAC,cAAA,CACAC,KAAA,KACAC,MAAA,CACAC,KAAA,KACAC,MAAA,OAGAC,cAAA,CACAC,SAAA,aAA6B","file":"static/js/90.bd152043.chunk.js","sourcesContent":["function wordSet(words) {\n  var set = {};\n  for (var i = 0; i < words.length; i++) set[words[i]] = true;\n  return set;\n}\nvar keywords = wordSet([\"_\", \"var\", \"let\", \"actor\", \"class\", \"enum\", \"extension\", \"import\", \"protocol\", \"struct\", \"func\", \"typealias\", \"associatedtype\", \"open\", \"public\", \"internal\", \"fileprivate\", \"private\", \"deinit\", \"init\", \"new\", \"override\", \"self\", \"subscript\", \"super\", \"convenience\", \"dynamic\", \"final\", \"indirect\", \"lazy\", \"required\", \"static\", \"unowned\", \"unowned(safe)\", \"unowned(unsafe)\", \"weak\", \"as\", \"is\", \"break\", \"case\", \"continue\", \"default\", \"else\", \"fallthrough\", \"for\", \"guard\", \"if\", \"in\", \"repeat\", \"switch\", \"where\", \"while\", \"defer\", \"return\", \"inout\", \"mutating\", \"nonmutating\", \"isolated\", \"nonisolated\", \"catch\", \"do\", \"rethrows\", \"throw\", \"throws\", \"async\", \"await\", \"try\", \"didSet\", \"get\", \"set\", \"willSet\", \"assignment\", \"associativity\", \"infix\", \"left\", \"none\", \"operator\", \"postfix\", \"precedence\", \"precedencegroup\", \"prefix\", \"right\", \"Any\", \"AnyObject\", \"Type\", \"dynamicType\", \"Self\", \"Protocol\", \"__COLUMN__\", \"__FILE__\", \"__FUNCTION__\", \"__LINE__\"]);\nvar definingKeywords = wordSet([\"var\", \"let\", \"actor\", \"class\", \"enum\", \"extension\", \"import\", \"protocol\", \"struct\", \"func\", \"typealias\", \"associatedtype\", \"for\"]);\nvar atoms = wordSet([\"true\", \"false\", \"nil\", \"self\", \"super\", \"_\"]);\nvar types = wordSet([\"Array\", \"Bool\", \"Character\", \"Dictionary\", \"Double\", \"Float\", \"Int\", \"Int8\", \"Int16\", \"Int32\", \"Int64\", \"Never\", \"Optional\", \"Set\", \"String\", \"UInt8\", \"UInt16\", \"UInt32\", \"UInt64\", \"Void\"]);\nvar operators = \"+-/*%=|&<>~^?!\";\nvar punc = \":;,.(){}[]\";\nvar binary = /^\\-?0b[01][01_]*/;\nvar octal = /^\\-?0o[0-7][0-7_]*/;\nvar hexadecimal = /^\\-?0x[\\dA-Fa-f][\\dA-Fa-f_]*(?:(?:\\.[\\dA-Fa-f][\\dA-Fa-f_]*)?[Pp]\\-?\\d[\\d_]*)?/;\nvar decimal = /^\\-?\\d[\\d_]*(?:\\.\\d[\\d_]*)?(?:[Ee]\\-?\\d[\\d_]*)?/;\nvar identifier = /^\\$\\d+|(`?)[_A-Za-z][_A-Za-z$0-9]*\\1/;\nvar property = /^\\.(?:\\$\\d+|(`?)[_A-Za-z][_A-Za-z$0-9]*\\1)/;\nvar instruction = /^\\#[A-Za-z]+/;\nvar attribute = /^@(?:\\$\\d+|(`?)[_A-Za-z][_A-Za-z$0-9]*\\1)/;\n//var regexp = /^\\/(?!\\s)(?:\\/\\/)?(?:\\\\.|[^\\/])+\\//\n\nfunction tokenBase(stream, state, prev) {\n  if (stream.sol()) state.indented = stream.indentation();\n  if (stream.eatSpace()) return null;\n  var ch = stream.peek();\n  if (ch == \"/\") {\n    if (stream.match(\"//\")) {\n      stream.skipToEnd();\n      return \"comment\";\n    }\n    if (stream.match(\"/*\")) {\n      state.tokenize.push(tokenComment);\n      return tokenComment(stream, state);\n    }\n  }\n  if (stream.match(instruction)) return \"builtin\";\n  if (stream.match(attribute)) return \"attribute\";\n  if (stream.match(binary)) return \"number\";\n  if (stream.match(octal)) return \"number\";\n  if (stream.match(hexadecimal)) return \"number\";\n  if (stream.match(decimal)) return \"number\";\n  if (stream.match(property)) return \"property\";\n  if (operators.indexOf(ch) > -1) {\n    stream.next();\n    return \"operator\";\n  }\n  if (punc.indexOf(ch) > -1) {\n    stream.next();\n    stream.match(\"..\");\n    return \"punctuation\";\n  }\n  var stringMatch;\n  if (stringMatch = stream.match(/(\"\"\"|\"|')/)) {\n    var tokenize = tokenString.bind(null, stringMatch[0]);\n    state.tokenize.push(tokenize);\n    return tokenize(stream, state);\n  }\n  if (stream.match(identifier)) {\n    var ident = stream.current();\n    if (types.hasOwnProperty(ident)) return \"type\";\n    if (atoms.hasOwnProperty(ident)) return \"atom\";\n    if (keywords.hasOwnProperty(ident)) {\n      if (definingKeywords.hasOwnProperty(ident)) state.prev = \"define\";\n      return \"keyword\";\n    }\n    if (prev == \"define\") return \"def\";\n    return \"variable\";\n  }\n  stream.next();\n  return null;\n}\nfunction tokenUntilClosingParen() {\n  var depth = 0;\n  return function (stream, state, prev) {\n    var inner = tokenBase(stream, state, prev);\n    if (inner == \"punctuation\") {\n      if (stream.current() == \"(\") ++depth;else if (stream.current() == \")\") {\n        if (depth == 0) {\n          stream.backUp(1);\n          state.tokenize.pop();\n          return state.tokenize[state.tokenize.length - 1](stream, state);\n        } else --depth;\n      }\n    }\n    return inner;\n  };\n}\nfunction tokenString(openQuote, stream, state) {\n  var singleLine = openQuote.length == 1;\n  var ch,\n    escaped = false;\n  while (ch = stream.peek()) {\n    if (escaped) {\n      stream.next();\n      if (ch == \"(\") {\n        state.tokenize.push(tokenUntilClosingParen());\n        return \"string\";\n      }\n      escaped = false;\n    } else if (stream.match(openQuote)) {\n      state.tokenize.pop();\n      return \"string\";\n    } else {\n      stream.next();\n      escaped = ch == \"\\\\\";\n    }\n  }\n  if (singleLine) {\n    state.tokenize.pop();\n  }\n  return \"string\";\n}\nfunction tokenComment(stream, state) {\n  var ch;\n  while (ch = stream.next()) {\n    if (ch === \"/\" && stream.eat(\"*\")) {\n      state.tokenize.push(tokenComment);\n    } else if (ch === \"*\" && stream.eat(\"/\")) {\n      state.tokenize.pop();\n      break;\n    }\n  }\n  return \"comment\";\n}\nfunction Context(prev, align, indented) {\n  this.prev = prev;\n  this.align = align;\n  this.indented = indented;\n}\nfunction pushContext(state, stream) {\n  var align = stream.match(/^\\s*($|\\/[\\/\\*]|[)}\\]])/, false) ? null : stream.column() + 1;\n  state.context = new Context(state.context, align, state.indented);\n}\nfunction popContext(state) {\n  if (state.context) {\n    state.indented = state.context.indented;\n    state.context = state.context.prev;\n  }\n}\nexport var swift = {\n  name: \"swift\",\n  startState: function startState() {\n    return {\n      prev: null,\n      context: null,\n      indented: 0,\n      tokenize: []\n    };\n  },\n  token: function token(stream, state) {\n    var prev = state.prev;\n    state.prev = null;\n    var tokenize = state.tokenize[state.tokenize.length - 1] || tokenBase;\n    var style = tokenize(stream, state, prev);\n    if (!style || style == \"comment\") state.prev = prev;else if (!state.prev) state.prev = style;\n    if (style == \"punctuation\") {\n      var bracket = /[\\(\\[\\{]|([\\]\\)\\}])/.exec(stream.current());\n      if (bracket) (bracket[1] ? popContext : pushContext)(state, stream);\n    }\n    return style;\n  },\n  indent: function indent(state, textAfter, iCx) {\n    var cx = state.context;\n    if (!cx) return 0;\n    var closing = /^[\\]\\}\\)]/.test(textAfter);\n    if (cx.align != null) return cx.align - (closing ? 1 : 0);\n    return cx.indented + (closing ? 0 : iCx.unit);\n  },\n  languageData: {\n    indentOnInput: /^\\s*[\\)\\}\\]]$/,\n    commentTokens: {\n      line: \"//\",\n      block: {\n        open: \"/*\",\n        close: \"*/\"\n      }\n    },\n    closeBrackets: {\n      brackets: [\"(\", \"[\", \"{\", \"'\", '\"', \"`\"]\n    }\n  }\n};"],"sourceRoot":""}